{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bereitstellen auf einem Batchendpunkt\n",
        "\n",
        "Stellen Sie sich vor, eine Klinik nimmt den ganzen Tag Patientenmessungen vor und speichert die Details für jeden Patienten in einer separaten Datei. Anschließend kann das Diabetesvorhersagemodell über Nacht verwendet werden, um alle Patientendaten des Tages als Batch zu verarbeiten und Vorhersagen zu generieren, die am nächsten Morgen bereitstehen. Damit kann die Klinik sich an Patienten wenden, für die ein Diabetesrisiko vorhergesagt wird. Mit Azure Machine Learning können Sie dies erreichen, indem Sie einen Batchendpunkt erstellen, den Sie in dieser Übung implementieren.\n",
        "\n",
        "## Vorbereitung\n",
        "\n",
        "Sie benötigen die neueste Version des Pakets **azureml-ai-ml**, um den Code in diesem Notebook auszuführen. Führen Sie die folgende Zelle aus, um zu überprüfen, ob das Paket installiert ist.\n",
        "\n",
        "> **Hinweis**:\n",
        "> Wenn das Paket **azure-ai-ml** nicht installiert ist, führen Sie `pip install azure-ai-ml` aus, um es zu installieren."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667816557578
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Herstellen einer Verbindung mit Ihrem Arbeitsbereich\n",
        "\n",
        "Sie können nun eine Verbindung mit Ihrem Arbeitsbereich herstellen, nachdem Sie die erforderlichen SDK-Pakete installiert haben.\n",
        "\n",
        "Um eine Verbindung mit einem Arbeitsbereich herzustellen, benötigen Sie Bezeichnerparameter: eine Abonnement-ID, einen Ressourcengruppennamen und einen Arbeitsbereichsnamen. Der Ressourcengruppenname und Arbeitsbereichsname sind bereits für Sie ausgefüllt. Sie müssen lediglich die Abonnement-ID angeben, um den Befehl zu vervollständigen.\n",
        "\n",
        "Um die erforderlichen Parameter zu finden, klicken Sie rechts oben in Studio auf das Abonnement und den Namen des Arbeitsbereichs. Rechts wird ein Bereich geöffnet.\n",
        "\n",
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> Kopieren Sie die Abonnement-ID, und ersetzen Sie **YOUR-SUBSCRIPTION-ID** durch den Wert, den Sie kopiert haben. </p>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Registrieren des Modells\n",
        "\n",
        "Bei Batchbereitstellungen können nur Modelle bereitgestellt werden, die im Arbeitsbereich registriert sind. Sie registrieren ein MLflow-Modell, das im lokalen Ordner `model` gespeichert ist. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667816564779
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Erstellen eines Batchendpunkts\n",
        "\n",
        "Ein Batchendpunkt ist ein HTTPS-Endpunkt, den Anwendungen aufrufen können, um einen Batchbewertungsauftrag auszulösen. Der Name eines Batchendpunkts muss innerhalb einer Azure-Region eindeutig sein. Mit der Funktion `datetime` generieren Sie einen eindeutigen Namen basierend auf dem aktuellen Datum und der aktuellen Uhrzeit. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667816570921
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "Um einen Endpunkt mit der `BatchEndpoint`-Klasse zu erstellen, müssen Sie den Namen und optional eine Beschreibung angeben. Nachdem Sie einen Endpunkt erstellt haben, stellen Sie ein Modell darauf bereit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> WICHTIG! Warten Sie, bis der Endpunkt erstellt wurde, ehe Sie fortfahren! In Studio sollte eine grüne Benachrichtigung eingeblendet werden. </p>\n",
        "\n",
        "## Erstellen der Bereitstellung\n",
        "\n",
        "Eine Einrichtung ist ein Satz von Ressourcen, die für das Hosting des Modells erforderlich sind, das die eigentliche Inferenz durchführt. Wir erstellen eine Bereitstellung für unseren Endpunkt mithilfe der `BatchDeployment`-Klasse. \n",
        "\n",
        "Da Sie ein MLflow-Modell bereitstellen, benötigen Sie weder ein Bewertungsskript noch müssen Sie die Umgebung definieren. Azure Machine Learning erstellt diese Ressourcen automatisch für Sie. Die Datei `MLmodel` im Ordner `model` wird verwendet, um die erwarteten Ein- und Ausgaben des Modells zu verstehen.\n",
        "\n",
        "Sie stellen ein Modell mit den folgenden Parametern bereit:\n",
        "\n",
        "- `name`: Name der Bereitstellung.\n",
        "- `description`: optionale Beschreibung, um zu verdeutlichen, was die Bereitstellung darstellt.\n",
        "- `endpoint_name`: Name des zuvor erstellten Endpunkts, auf dem das Modell bereitgestellt werden soll.\n",
        "- `model`: Name des registrierten Modells.\n",
        "- `compute`: Compute-Instanz, die beim Aufrufen des bereitgestellten Modells verwendet werden soll, um Vorhersagen zu generieren.\n",
        "- `instance_count`: Anzahl der Serverknoten, die zum Generieren von Vorhersagen verwendet werden sollen\n",
        "- `max_concurrency_per_instance`: maximale Anzahl paralleler Bewertungsskriptausführungen pro Serverknoten\n",
        "- `mini_batch_size`: Anzahl der pro Bewertungsskriptausführung übergebenen Dateien\n",
        "- `output_action`: Jede neue Vorhersage wird als neue Zeile an die Ausgabedatei angefügt.\n",
        "- `output_file_name`: Datei, an die Vorhersagen angefügt werden.\n",
        "- `retry_settings`: Einstellungen, wenn bei einem Minibatch ein Fehler auftritt.\n",
        "- `logging_level`: die Ausführlichkeitsstufe des Protokolls. Zulässige Werte sind `warning`, `info` und `debug`. \n",
        "\n",
        "Wenn Sie die folgende Zelle ausführen, wird die Bereitstellung konfiguriert und erstellt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667816601458
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> WICHTIG! Warten Sie, bis die Bereitstellung abgeschlossen ist, ehe Sie fortfahren! In Studio sollte eine grüne Benachrichtigung eingeblendet werden. </p>\n",
        "\n",
        "Sie können mehrere Modelle auf einem Endpunkt bereitstellen. Sie können die Standardbereitstellung festlegen, um anzugeben, welches Modell beim Aufrufen eines Batchendpunkts standardmäßig verwendet werden soll."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> WICHTIG! Warten Sie, bis die Standardbereitstellung festgelegt ist, ehe Sie fortfahren! In Studio sollte eine grüne Benachrichtigung eingeblendet werden. </p>\n",
        "\n",
        "## Vorbereiten der Daten für Batchvorhersagen\n",
        "\n",
        "Im Ordner `data` finden Sie CSV-Dateien mit Daten ohne Bezeichnung. Sie erstellen eine Datenressource, die auf die Dateien im Ordner `data` verweist, die als Eingabe für den Batchauftrag dienen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667817132589
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Übermitteln des Auftrags\n",
        "\n",
        "Sie haben ein Modell für einen Batchendpunkt bereitgestellt und verfügen über eine Datenressource ohne Bezeichnung. Nun können Sie den Endpunkt aufrufen, um Vorhersagen für die Daten ohne Bezeichnung zu generieren.\n",
        "\n",
        "Zunächst legen Sie die Eingabe fest, indem Sie auf die registrierte Datenressource verweisen. Anschließend rufen Sie den Endpunkt auf, der einen Pipelineauftrag übermittelt. Sie können die URL des Auftrags verwenden, um ihn in Studio zu überwachen. Der Auftrag enthält einen untergeordneten Auftrag, der die Ausführung des (generierten) Bewertungsskripts zum Abrufen der Vorhersagen darstellt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Abrufen der Ergebnisse\n",
        "\n",
        "Wenn der Pipelineauftrag, der den Batchendpunkt aufruft, abgeschlossen ist, können Sie die Ergebnisse anzeigen. Alle Vorhersagen werden in der Datei `predictions.csv` gesammelt, die im Standarddatenspeicher gespeichert ist. Sie können die Datei herunterladen und die Daten visualisieren, indem Sie die folgenden Zellen ausführen. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667817134786
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import BatchEndpoint\n",
        "\n",
        "# create a batch endpoint\n",
        "endpoint = BatchEndpoint(\n",
        "    name=endpoint_name,\n",
        "    description=\"A batch endpoint for classifying diabetes in patients\",\n",
        ")\n",
        "\n",
        "ml_client.batch_endpoints.begin_create_or_update(endpoint)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> IMPORTANT! Wait until the endpoint is created before continuing! A green notification should appear in the studio. </p>\n",
        "\n",
        "## Create the deployment\n",
        "\n",
        "A deployment is a set of resources required for hosting the model that does the actual inferencing. We will create a deployment for our endpoint using the `BatchDeployment` class. \n",
        "\n",
        "Since you're deploying an MLflow model, you don't need a scoring script or define the environment. Azure Machine Learning will automatically create those assets for you. The `MLmodel` file in the `model` folder is used to understand what the expected inputs and outputs are of the model.\n",
        "\n",
        "You'll deploy a model with the following parameters:\n",
        "\n",
        "- `name`: Name of the deployment.\n",
        "- `description`: Optional description to further clarify what the deployment represents.\n",
        "- `endpoint_name`: Name of the previously created endpoint the model should be deployed to.\n",
        "- `model`: Name of the registered model.\n",
        "- `compute`: Compute to be used when invoking the deployed model to generate predictions.\n",
        "- `instance_count`: Count of compute nodes to use for generating predictions.\n",
        "- `max_concurrency_per_instance`: Maximum number of parallel scoring script runs per compute node.\n",
        "- `mini_batch_size`: Number of files passed per scoring script run.\n",
        "- `output_action`: Each new prediction will be appended as a new row to the output file.\n",
        "- `output_file_name`: File to which predictions will be appended.\n",
        "- `retry_settings`: Settings for a mini-batch fails.\n",
        "- `logging_level`: The log verbosity level. Allowed values are `warning`, `info`, and `debug`. \n",
        "\n",
        "Running the following cell will configure and create the deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667817147601
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import BatchDeployment, BatchRetrySettings\n",
        "from azure.ai.ml.constants import BatchDeploymentOutputAction\n",
        "\n",
        "deployment = BatchDeployment(\n",
        "    name=\"classifier-diabetes-mlflow\",\n",
        "    description=\"A diabetes classifier\",\n",
        "    endpoint_name=endpoint.name,\n",
        "    model=model,\n",
        "    compute=\"aml-cluster\",\n",
        "    instance_count=2,\n",
        "    max_concurrency_per_instance=2,\n",
        "    mini_batch_size=2,\n",
        "    output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
        "    output_file_name=\"predictions.csv\",\n",
        "    retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n",
        "    logging_level=\"info\",\n",
        ")\n",
        "ml_client.batch_deployments.begin_create_or_update(deployment)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> IMPORTANT! Wait until the deployment is completed before continuing! A green notification should appear in the studio. </p>\n",
        "\n",
        "You can deploy multiple models to an endpoint. You can set the default deployment to specify which model should be used by default when calling a batch endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667816665145
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "endpoint.defaults = {}\n",
        "\n",
        "endpoint.defaults[\"deployment_name\"] = deployment.name\n",
        "\n",
        "ml_client.batch_endpoints.begin_create_or_update(endpoint)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> IMPORTANT! Wait until the default deployment is set before continuing! A green notification should appear in the studio. </p>\n",
        "\n",
        "## Prepare the data for batch predictions\n",
        "\n",
        "In the `data` folder you'll find CSV files with unlabeled data. You'll create a data asset that points to the files in the `data` folder, which you'll use as input for the batch job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667816672949
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "data_path = \"./data\"\n",
        "dataset_name = \"patient-data-unlabeled\"\n",
        "\n",
        "patient_dataset_unlabeled = Data(\n",
        "    path=data_path,\n",
        "    type=AssetTypes.URI_FOLDER,\n",
        "    description=\"An unlabeled dataset for diabetes classification\",\n",
        "    name=dataset_name,\n",
        ")\n",
        "ml_client.data.create_or_update(patient_dataset_unlabeled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667816675432
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "patient_dataset_unlabeled = ml_client.data.get(\n",
        "    name=\"patient-data-unlabeled\", label=\"latest\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submit the job\n",
        "\n",
        "Now that you have deployed a model to a batch endpoint, and have an unlabeled data asset, you're ready to invoke the endpoint to generate predictions on the unlabeled data.\n",
        "\n",
        "First, you'll define the input by referring to the registered data asset. Then, you'll invoke the endpoint, which will submit a pipeline job. You can use the job URL to monitor it in the Studio. The job will contain a child job that represents the running of the (generated) scoring script to get the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667816677507
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "input = Input(type=AssetTypes.URI_FOLDER, path=patient_dataset_unlabeled.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667817161221
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "job = ml_client.batch_endpoints.invoke(\n",
        "    endpoint_name=endpoint.name, \n",
        "    input=input)\n",
        "\n",
        "ml_client.jobs.get(job.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get the results\n",
        "\n",
        "When the pipeline job that invokes the batch endpoint is completed, you can view the results. All predictions are collected in the `predictions.csv` file that is stored in the default datastore. You can download the file and visualize the data by running the following cells. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667817536367
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "ml_client.jobs.download(name=job.name, download_path=\".\", output_name=\"score\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667817544534
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "with open(\"predictions.csv\", \"r\") as f:\n",
        "    data = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667817550830
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from ast import literal_eval\n",
        "import pandas as pd\n",
        "\n",
        "score = pd.DataFrame(\n",
        "    literal_eval(data.replace(\"\\n\", \",\")), columns=[\"file\", \"prediction\"]\n",
        ")\n",
        "score"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}