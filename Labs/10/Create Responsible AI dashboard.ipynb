{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Erstellen eines Dashboards für verantwortungsvolle\u00A0KI zum Auswerten Ihrer Modelle\n",
        "\n",
        "Wenn Sie Ihre Machine Learning-Modelle vergleichen und auswerten, sollten Sie mehr als nur ihre Leistungsmetrik überprüfen. Mit Azure Machine Learning können Sie ein Dashboard für verantwortungsvolle\u00A0KI erstellen, um die Leistung des Modells für verschiedene Kohorten der Daten zu untersuchen. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vorbereiten der Daten\n",
        "\n",
        "Um das Dashboard für verantwortungsvolle\u00A0KI zu erstellen, benötigen Sie ein Trainings- und Testdataset, das als Parquet-Dateien gespeichert und als Datenressourcen registriert ist.\n",
        "\n",
        "Die Daten werden derzeit als CSV-Dateien gespeichert. Wir konvertieren sie in Parquet-Dateien. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025462688
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Ehe Sie fortfahren\n",
        "\n",
        "Sie benötigen die neueste Version des Pakets **azureml-ai-ml**, um den Code in diesem Notebook auszuführen. Führen Sie die folgende Zelle aus, um zu überprüfen, ob das Paket installiert ist.\n",
        "\n",
        "> **Hinweis**:\n",
        "> Wenn das Paket **azure-ai-ml** nicht installiert ist, führen Sie `pip install azure-ai-ml` aus, um es zu installieren."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025466902
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Herstellen einer Verbindung mit Ihrem Arbeitsbereich\n",
        "\n",
        "Sie können nun eine Verbindung mit Ihrem Arbeitsbereich herstellen, nachdem Sie die erforderlichen SDK-Pakete installiert haben.\n",
        "\n",
        "Um eine Verbindung mit einem Arbeitsbereich herzustellen, benötigen Sie Bezeichnerparameter: eine Abonnement-ID, einen Ressourcengruppennamen und einen Arbeitsbereichsnamen. Der Ressourcengruppenname und Arbeitsbereichsname sind bereits für Sie ausgefüllt. Sie müssen lediglich die Abonnement-ID angeben, um den Befehl zu vervollständigen.\n",
        "\n",
        "Um die erforderlichen Parameter zu finden, klicken Sie rechts oben in Studio auf das Abonnement und den Namen des Arbeitsbereichs. Rechts wird ein Bereich geöffnet.\n",
        "\n",
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> Kopieren Sie die Abonnement-ID, und ersetzen Sie **YOUR-SUBSCRIPTION-ID** durch den Wert, den Sie kopiert haben. </p>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Erstellen der Datenressourcen\n",
        "\n",
        "Um das Dashboard für verantwortungsvolle\u00A0KI zu erstellen, müssen Sie die Trainings- und Testdatasets als **MLtable**-Datenressourcen registrieren. Die MLtable-Datenressourcen verweisen auf die Parquet-Dateien, die Sie zuvor erstellt haben."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025474944
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Erstellen der Pipeline zum Erstellen des Dashboards für verantwortungsvolle\u00A0KI\n",
        "\n",
        "Zum Erstellen des Dashboards erstellen Sie eine Pipeline mit vordefinierten Komponenten, die standardmäßig im Azure Machine Learning-Arbeitsbereich registriert sind."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Registrieren des Modells\n",
        "\n",
        "Ein Machine Learning-Modell wurde bereits für Sie trainiert. Das Modell sagt voraus, ob ein Patient an Diabetes leidet. Alle Modelldateien werden im Ordner `model` gespeichert. \n",
        "\n",
        "Registrieren Sie das Modell, indem Sie auf den Ordner `model` und seinen Inhalt zeigen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025488380
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Erstellen der Pipeline\n",
        "\n",
        "Um das Dashboard für verantwortungsvolle\u00A0KI zu erstellen, erstellen Sie eine Pipeline mithilfe der vordefinierten Komponenten. Sie können auswählen, welche Komponenten verwendet werden sollen und welche Features Sie in Ihr Dashboard aufnehmen möchten. Sie erstellen ein Dashboard, das Fehleranalyse und Modellinterpretierbarkeit umfasst. \n",
        "\n",
        "Neben den Features für verantwortungsvolle\u00A0KI muss eine Pipeline zur Erstellung eines Dashboards am Anfang eine Komponente enthalten, die das Dashboard erstellt, und am Ende eine Komponente, die alle generierten Erkenntnisse sammelt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025518893
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "Wenn Sie alle gewünschten Komponenten abgerufen haben, können Sie die Pipeline erstellen und die Komponenten in der richtigen Reihenfolge verbinden:\n",
        "\n",
        "1. Erstellen Sie das Dashboard.\n",
        "1. Fügen Sie die Fehleranalyse hinzu.\n",
        "1. Fügen Sie Erklärungen hinzu.\n",
        "1. Sammeln Sie alle Erkenntnisse, und visualisieren Sie sie im Dashboard."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nachdem die Pipeline erstellt wurde, müssen Sie die beiden erforderlichen Eingaben definieren: das Trainings- und das Testdataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025520971
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "Schließlich fügen wir alles zusammen: Weisen Sie der Pipeline die Eingaben zu, und legen Sie die Zielspalte (die vorhergesagte Bezeichnung) fest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025542446
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Führen Sie die Pipeline aus.\n",
        "\n",
        "Sobald Sie die Pipeline erfolgreich erstellt haben, können Sie sie übermitteln. Mit dem folgenden Code wird die Pipeline übermittelt und der Status der Pipeline überprüft. Sie können den Status der Pipeline auch in Studio anzeigen. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wenn die Pipeline abgeschlossen ist, können Sie das Dashboard in Studio überprüfen. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025587559
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Get handle to azureml registry for the RAI built in components\n",
        "registry_name = \"azureml\"\n",
        "ml_client_registry = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=subscription_id,\n",
        "    resource_group_name=resource_group,\n",
        "    registry_name=registry_name,\n",
        ")\n",
        "print(ml_client_registry)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Register the model\n",
        "\n",
        "A machine learning model has already been trained for you. The model predicts whether a patient has diabetes. All model files are stored in the `model` folder. \n",
        "\n",
        "Register the model by pointing to the `model` folder and its contents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025596451
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Model\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "file_model = Model(\n",
        "    path=\"model\",\n",
        "    type=AssetTypes.MLFLOW_MODEL,\n",
        "    name=\"local-mlflow-diabetes\",\n",
        "    description=\"Model created from local file.\",\n",
        ")\n",
        "model = ml_client.models.create_or_update(file_model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build the pipeline\n",
        "\n",
        "To create the responsible AI dashboard, you'll create a pipeline using the prebuilt components. You can choose which components to use, and which features you want to include in your dashboard. You'll create a dashboard that includes error analysis and model interpretability. \n",
        "\n",
        "Next to the responsible AI features, a pipeline to build a dashboard needs to include a component at the start to construct the dashboard, and a component at the end to gather all generated insights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025619196
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "model_name = model.name\n",
        "expected_model_id = f\"{model_name}:1\"\n",
        "azureml_model_id = f\"azureml:{expected_model_id}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025626888
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "label = \"latest\"\n",
        "\n",
        "rai_constructor_component = ml_client_registry.components.get(\n",
        "    name=\"microsoft_azureml_rai_tabular_insight_constructor\", label=label\n",
        ")\n",
        "\n",
        "# we get latest version and use the same version for all components\n",
        "version = rai_constructor_component.version\n",
        "print(\"The current version of RAI built-in components is: \" + version)\n",
        "\n",
        "rai_erroranalysis_component = ml_client_registry.components.get(\n",
        "    name=\"microsoft_azureml_rai_tabular_erroranalysis\", version=version\n",
        ")\n",
        "\n",
        "rai_explanation_component = ml_client_registry.components.get(\n",
        "    name=\"microsoft_azureml_rai_tabular_explanation\", version=version\n",
        ")\n",
        "\n",
        "rai_gather_component = ml_client_registry.components.get(\n",
        "    name=\"microsoft_azureml_rai_tabular_insight_gather\", version=version\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When you've retrieved all components you want to use, you can build the pipeline and connect the components in the appropriate order:\n",
        "\n",
        "1. Construct the dashboard.\n",
        "1. Add error analysis.\n",
        "1. Add explanations.\n",
        "1. Gather all insights and visualize them in the dashboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677026156980
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input, dsl\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "compute_name = \"aml-cluster\"\n",
        "\n",
        "@dsl.pipeline(\n",
        "    compute=compute_name,\n",
        "    description=\"RAI insights on diabetes data\",\n",
        "    experiment_name=f\"RAI_insights_{model_name}\",\n",
        ")\n",
        "def rai_decision_pipeline(\n",
        "    target_column_name, train_data, test_data\n",
        "):\n",
        "    # Initiate the RAIInsights\n",
        "    create_rai_job = rai_constructor_component(\n",
        "        title=\"RAI dashboard diabetes\",\n",
        "        task_type=\"classification\",\n",
        "        model_info=expected_model_id,\n",
        "        model_input=Input(type=AssetTypes.MLFLOW_MODEL, path=azureml_model_id),\n",
        "        train_dataset=train_data,\n",
        "        test_dataset=test_data,\n",
        "        target_column_name=target_column_name,\n",
        "    )\n",
        "    create_rai_job.set_limits(timeout=30)\n",
        "\n",
        "    # Add error analysis\n",
        "    error_job = rai_erroranalysis_component(\n",
        "        rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
        "    )\n",
        "    error_job.set_limits(timeout=10)\n",
        "\n",
        "    # Add explanations\n",
        "    explanation_job = rai_explanation_component(\n",
        "        rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
        "        comment=\"add explanation\", \n",
        "    )\n",
        "    explanation_job.set_limits(timeout=10)\n",
        "\n",
        "    # Combine everything\n",
        "    rai_gather_job = rai_gather_component(\n",
        "        constructor=create_rai_job.outputs.rai_insights_dashboard,\n",
        "        insight_3=error_job.outputs.error_analysis,\n",
        "        insight_4=explanation_job.outputs.explanation,\n",
        "    )\n",
        "    rai_gather_job.set_limits(timeout=10)\n",
        "\n",
        "    rai_gather_job.outputs.dashboard.mode = \"upload\"\n",
        "\n",
        "    return {\n",
        "        \"dashboard\": rai_gather_job.outputs.dashboard,\n",
        "    }"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now the pipeline has been built, you need to define the two necessary inputs: the training and test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025638275
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input\n",
        "target_feature = \"Diabetic\"\n",
        "\n",
        "diabetes_train_pq = Input(\n",
        "    type=\"mltable\",\n",
        "    path=f\"azureml:{input_train_data}:{data_version}\",\n",
        "    mode=\"download\",\n",
        ")\n",
        "diabetes_test_pq = Input(\n",
        "    type=\"mltable\",\n",
        "    path=f\"azureml:{input_test_data}:{data_version}\",\n",
        "    mode=\"download\",\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we'll put everything together: assign the inputs to the pipeline and set the target column (the predicted label)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677026333108
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "from azure.ai.ml import Output\n",
        "\n",
        "# Pipeline to construct the RAI Insights\n",
        "insights_pipeline_job = rai_decision_pipeline(\n",
        "    target_column_name=\"Diabetic\",\n",
        "    train_data=diabetes_train_pq,\n",
        "    test_data=diabetes_test_pq,\n",
        ")\n",
        "\n",
        "# Workaround to enable the download\n",
        "rand_path = str(uuid.uuid4())\n",
        "insights_pipeline_job.outputs.dashboard = Output(\n",
        "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/dashboard/\",\n",
        "    mode=\"upload\",\n",
        "    type=\"uri_folder\",\n",
        ")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the pipeline\n",
        "\n",
        "When you've successfully built the pipeline, you can submit it. The following code will submit the pipeline and check the status of the pipeline. You can also view the pipeline's status in the studio. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677026340892
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import PipelineJob\n",
        "from IPython.core.display import HTML\n",
        "from IPython.display import display\n",
        "import time\n",
        "\n",
        "def submit_and_wait(ml_client, pipeline_job) -> PipelineJob:\n",
        "    created_job = ml_client.jobs.create_or_update(pipeline_job)\n",
        "    assert created_job is not None\n",
        "\n",
        "    print(\"Pipeline job can be accessed in the following URL:\")\n",
        "    display(HTML('<a href=\"{0}\">{0}</a>'.format(created_job.studio_url)))\n",
        "\n",
        "    while created_job.status not in [\n",
        "        \"Completed\",\n",
        "        \"Failed\",\n",
        "        \"Canceled\",\n",
        "        \"NotResponding\",\n",
        "    ]:\n",
        "        time.sleep(30)\n",
        "        created_job = ml_client.jobs.get(created_job.name)\n",
        "        print(\"Latest status : {0}\".format(created_job.status))\n",
        "    assert created_job.status == \"Completed\"\n",
        "    return created_job\n",
        "\n",
        "\n",
        "# This is the actual submission\n",
        "insights_job = submit_and_wait(ml_client, insights_pipeline_job)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When the pipeline is completed, you can review the dashboard in the studio. "
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}