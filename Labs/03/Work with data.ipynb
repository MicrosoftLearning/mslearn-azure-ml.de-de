{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Arbeiten mit Daten\n",
        "\n",
        "Daten sind die Grundlage für den Aufbau von Machine Learning-Modellen. Die zentrale Verwaltung von Daten in der Cloud und deren Zugriff auf Teams von wissenschaftlichen Fachkräften für Daten, die Experimente und Trainingsmodelle auf mehreren Arbeitsstationen und Computezielen ausführen, ist ein wichtiger Bestandteil jeder professionellen Data Science-Lösung.\n",
        "\n",
        "In diesem Notebook untersuchen Sie zwei Azure Machine Learning-Objekte für das Arbeiten mit Daten: *Datenspeicher* und *Datenressourcen*.\n",
        "\n",
        "## Vorbereitung\n",
        "\n",
        "Sie benötigen die neueste Version des Pakets **azureml-ai-ml**, um den Code in diesem Notebook auszuführen. Führen Sie die folgende Zelle aus, um zu überprüfen, ob das Paket installiert ist.\n",
        "\n",
        "> **Hinweis**:\n",
        "> Wenn das Paket **azure-ai-ml** nicht installiert ist, führen Sie `pip install azure-ai-ml` aus, um es zu installieren."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666789326586
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Herstellen einer Verbindung mit Ihrem Arbeitsbereich\n",
        "\n",
        "Sie können nun eine Verbindung mit Ihrem Arbeitsbereich herstellen, nachdem Sie die erforderlichen SDK-Pakete installiert haben.\n",
        "\n",
        "Um eine Verbindung mit einem Arbeitsbereich herzustellen, benötigen Sie Bezeichnerparameter: eine Abonnement-ID, einen Ressourcengruppennamen und einen Arbeitsbereichsnamen. Der Ressourcengruppenname und Arbeitsbereichsname sind bereits für Sie ausgefüllt. Sie müssen lediglich die Abonnement-ID angeben, um den Befehl zu vervollständigen.\n",
        "\n",
        "Um die erforderlichen Parameter zu finden, klicken Sie rechts oben in Studio auf das Abonnement und den Namen des Arbeitsbereichs. Rechts wird ein Bereich geöffnet.\n",
        "\n",
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> Kopieren Sie die Abonnement-ID, und ersetzen Sie **YOUR-SUBSCRIPTION-ID** durch den Wert, den Sie kopiert haben. </p>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Auflisten der Datenspeicher\n",
        "\n",
        "Wenn Sie den Azure Machine Learning-Arbeitsbereich erstellen, wird auch ein Azure Storage-Konto erstellt. Dieses Speicherkonto umfasst Blob- und Dateispeicher und wird automatisch als **Datenspeicher** mit Ihrem Arbeitsbereich verbunden. Sie können alle Datenspeicher auflisten, die mit Ihrem Arbeitsbereich verbunden sind:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666789343369
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "Beachten Sie den `workspaceblobstore`, der sich mit dem Container **azureml-blobstore-...** verbindet, den Sie zuvor erkundet haben. Der `workspacefilestore` stellt eine Verbindung mit der Dateifreigabe **code-...** her."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Erstellen eines Datenspeichers\n",
        "\n",
        "Wenn Sie einen anderen Azure-Speicherdienst mit dem Azure Machine Learning-Arbeitsbereich verbinden möchten, können Sie einen Datenspeicher erstellen. Beachten Sie, dass beim Erstellen eines Datenspeichers die Verbindung zwischen Ihrem Arbeitsbereich und dem Speicher und nicht der Speicherdienst selbst erstellt wird. \n",
        "\n",
        "Um einen Datenspeicher zu erstellen und eine Verbindung mit einem (bereits vorhandenen) Speicher herzustellen, müssen Sie Folgendes angeben:\n",
        "\n",
        "- Die Klasse, mit der angegeben werden soll, mit welchem Speicherdienst Sie eine Verbindung herstellen möchten. Im folgenden Beispiel wird eine Verbindung mit einem Blobspeicher (`AzureBlobDatastore`) hergestellt.\n",
        "- `name`: der Anzeigename des Datenspeichers im Azure Machine Learning-Arbeitsbereich.\n",
        "- `description`: optionale Beschreibung mit weiteren Informationen zum Datenspeicher.\n",
        "- `account_name`: der Name des Azure Storage-Kontos.\n",
        "- `container_name`: der Name des Containers zum Speichern von Blobs im Azure Storage-Konto.\n",
        "- `credentials`: Geben Sie die Authentifizierungsmethode und die Anmeldeinformationen für die Authentifizierung an. Im folgenden Beispiel wird ein Kontoschlüssel verwendet.\n",
        "\n",
        "**Wichtig**: \n",
        "- Ersetzen Sie **YOUR-STORAGE-ACCOUNT-NAME** durch den Namen des Speicherkontos, das automatisch für Sie erstellt wurde. \n",
        "- Ersetzen Sie **XXXX-XXXX** in `account_key` durch den Kontoschlüssel Ihres Azure Storage-Kontos. \n",
        "\n",
        "Denken Sie daran, dass Sie den Kontoschlüssel abrufen können, indem Sie zum [Azure-Portal](https://portal.azure.com) und dann zu Ihrem Speicherkonto navigieren. Kopieren Sie auf der Registerkarte **Zugriffsschlüssel** den Wert von **Schlüssel** für key1 oder key2. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Listen Sie die Datenspeicher erneut auf, um zu prüfen, ob ein neuer Datenspeicher mit dem Namen `blob_training_data` erstellt wurde:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790805418
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Erstellen von Datenressourcen\n",
        "\n",
        "Um auf einen bestimmten Ordner oder eine bestimmte Datei in einem Datenspeicher zu verweisen, können Sie Datenressourcen erstellen. Es gibt drei Arten von Datenressourcen:\n",
        "\n",
        "- `URI_FILE` verweist auf eine bestimmte Datei.\n",
        "- `URI_FOLDER` verweist auf einen bestimmten Ordner.\n",
        "- `MLTABLE` verweist auf eine MLTable-Datei, die angibt, wie eine oder mehrere Dateien in einem Ordner gelesen werden sollen.\n",
        "\n",
        "Sie erstellen alle drei Arten von Datenressourcen, um die Unterschiede kennenzulernen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Zum Erstellen der Datenressource `URI_FILE` müssen Sie einen Pfad angeben, der auf eine bestimmte Datei zeigt. Der Pfad kann ein lokaler oder UNC-Pfad sein.\n",
        "\n",
        "Im folgenden Beispiel erstellen Sie eine Datenressource, indem Sie auf einen *lokalen* Pfad verweisen. Um sicherzustellen, dass die Daten beim Arbeiten mit dem Azure Machine Learning-Arbeitsbereich stets verfügbar sind, werden lokale Dateien automatisch in den Standarddatenspeicher hochgeladen. In diesem Fall wird die Datei in den `diabetes.csv` Ordner **LocalUpload** im Datenspeicher **workspaceblobstore** hochgeladen. \n",
        "\n",
        "Führen Sie die folgende Zelle aus, um eine Datenressource aus einer lokalen Datei zu erstellen:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Zum Erstellen der Datenressource `URI_FOLDER` müssen Sie einen Pfad angeben, der auf einen bestimmten Ordner zeigt. Der Pfad kann ein lokaler oder UNC-Pfad sein.\n",
        "\n",
        "Im folgenden Beispiel erstellen Sie eine Datenressource, indem Sie auf einen *Cloudpfad* verweisen. Der Pfad muss noch nicht vorhanden sein. Der Ordner wird erstellt, wenn Daten in den Pfad hochgeladen werden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790818340
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "Um die Datenressource `MLTable` zu erstellen, müssen Sie einen Pfad angeben, der auf einen Ordner mit einer MLTable-Datei zeigt. Der Pfad kann ein lokaler oder UNC-Pfad sein. \n",
        "\n",
        "Im folgenden Beispiel erstellen Sie eine Datenressource, indem Sie auf einen *lokalen* Pfad mit einer MLTable- und CSV-Datei verweisen. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Um zu überprüfen, ob die neuen Datenressourcen erstellt wurden, können Sie alle Datenressourcen im Arbeitsbereich erneut auflisten:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790835295
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Lesen von Daten im Notebook\n",
        "\n",
        "Zunächst sollten Sie in Notebooks mit Datenressourcen arbeiten, um die Daten zu erkunden und mit Machine Learning-Modellen zu experimentieren. Beliebige Datenressourcen des Typs `URI_FILE` oder `URI_FOLDER` werden so gelesen, wie Daten normalerweise gelesen werden. Um beispielsweise eine CSV-Datei zu lesen, auf die eine Datenressource zeigt, können Sie die pandas-Funktion `read_csv()` verwenden. \n",
        "\n",
        "Eine Datenressource des Typs `MLTable` wurde bereits von der **MLTable**-Datei *gelesen*, die das Schema und die Art der Interpretation der Daten angibt. Da die Daten bereits *gelesen* wurden, können Sie eine MLTable-Datenressource problemlos in einen pandas-Dataframe konvertieren. \n",
        "\n",
        "Sie müssen die Bibliothek `mltable` installieren (was Sie im Terminal getan haben). Anschließend können Sie die Datenressource in einen Dataframe konvertieren und die Daten visualisieren.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Verwenden von Daten in einem Auftrag\n",
        "\n",
        "Nach Verwendung in einem Notebook zum Experimentieren. Sie können Machine Learning-Modelle mit Skripts trainieren. Ein Skript kann als Auftrag ausgeführt werden, und für jeden Auftrag können Sie Ein- und Ausgaben angeben. \n",
        "\n",
        "Sie können als Ein- oder Ausgaben eines Auftrags entweder **Datenressourcen** oder **Datenspeicherpfade** verwenden. \n",
        "\n",
        "Mit den nachstehenden Zellen wird das Skript **move-data.py** im Ordner **src** erstellt. Das Skript liest die Eingabedaten mit der Funktion `read_csv()`. Das Skript speichert dann die Daten als CSV-Datei im Ausgabepfad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Um einen Auftrag zu übermitteln, der das Skript **move-data.py** ausführt, führen Sie die folgende Zelle aus. \n",
        "\n",
        "Der Auftrag ist so konfiguriert, dass er die Datenressource `diabetes-local` verwendet, die auf die lokale Datei **diabetes.csv** als Eingabe zeigt. Die Ausgabe ist ein Pfad, der auf einen Ordner im neuen Datenspeicher `blob_training_data` zeigt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790852019
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "my_path = './data/diabetes.csv'\n",
        "\n",
        "my_data = Data(\n",
        "    path=my_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    description=\"Data asset pointing to a local file, automatically uploaded to the default datastore\",\n",
        "    name=\"diabetes-local\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To create a `URI_FOLDER` data asset, you have to specify a path that points to a specific folder. The path can be a local path or cloud path.\n",
        "\n",
        "In the example below, you'll create a data asset by referencing a *cloud* path. The path doesn't have to exist yet. The folder will be created when data is uploaded to the path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666793449117
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "datastore_path = 'azureml://datastores/blob_training_data/paths/data-asset-path/'\n",
        "\n",
        "my_data = Data(\n",
        "    path=datastore_path,\n",
        "    type=AssetTypes.URI_FOLDER,\n",
        "    description=\"Data asset pointing to data-asset-path folder in datastore\",\n",
        "    name=\"diabetes-datastore-path\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To create a `MLTable` data asset, you have to specify a path that points to a folder which contains a MLTable file. The path can be a local path or cloud path. \n",
        "\n",
        "In the example below, you'll create a data asset by referencing a *local* path which contains an MLTable and CSV file. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790884342
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "local_path = 'data/'\n",
        "\n",
        "my_data = Data(\n",
        "    path=local_path,\n",
        "    type=AssetTypes.MLTABLE,\n",
        "    description=\"MLTable pointing to diabetes.csv in data folder\",\n",
        "    name=\"diabetes-table\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To verify that the new data assets have been created, you can list all data assets in the workspace again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790894246
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "datasets = ml_client.data.list()\n",
        "for ds_name in datasets:\n",
        "    print(ds_name.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Read data in notebook\n",
        "\n",
        "Initially, you may want to work with data assets in notebooks, to explore the data and experiment with machine learning models. Any `URI_FILE` or `URI_FOLDER` type data assets are read as you would normally read data. For example, to read a CSV file a data asset points to, you can use the pandas function `read_csv()`. \n",
        "\n",
        "A `MLTable` type data asset is already *read* by the **MLTable** file, which specifies the schema and how to interpret the data. Since the data is already *read*, you can easily convert a MLTable data asset to a pandas dataframe. \n",
        "\n",
        "You'll need to install the `mltable` library (which you did in the terminal). Then, you can convert the data asset to a dataframe and visualize the data.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666792246101
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import mltable\n",
        "\n",
        "registered_data_asset = ml_client.data.get(name='diabetes-table', version=1)\n",
        "tbl = mltable.load(f\"azureml:/{registered_data_asset.id}\")\n",
        "df = tbl.to_pandas_dataframe()\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Use data in a job\n",
        "\n",
        "After using a notebook for experimentation. You can use scripts to train machine learning models. A script can be run as a job, and for each job you can specify inputs and outputs. \n",
        "\n",
        "You can use either **data assets** or **datastore paths** as inputs or outputs of a job. \n",
        "\n",
        "The cells below creates the **move-data.py** script in the **src** folder. The script reads the input data with the `read_csv()` function. The script then stores the data as a CSV file in the output path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# create a folder for the script files\n",
        "script_folder = 'src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%writefile $script_folder/move-data.py\n",
        "# import libraries\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def main(args):\n",
        "    # read data\n",
        "    df = get_data(args.input_data)\n",
        "\n",
        "    output_df = df.to_csv((Path(args.output_datastore) / \"diabetes.csv\"), index = False)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # Count the rows and print the result\n",
        "    row_count = (len(df))\n",
        "    print('Analyzing {} rows of data'.format(row_count))\n",
        "    \n",
        "    return df\n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--input_data\", dest='input_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--output_datastore\", dest='output_datastore',\n",
        "                        type=str)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To submit a job that runs the **move-data.py** script, run the cell below. \n",
        "\n",
        "The job is configured to use the data asset `diabetes-local`, pointing to the local **diabetes.csv** file as input. The output is a path pointing to a folder in the new datastore `blob_training_data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666794414231
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input, Output\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml import command\n",
        "\n",
        "# configure input and output\n",
        "my_job_inputs = {\n",
        "    \"local_data\": Input(type=AssetTypes.URI_FILE, path=\"azureml:diabetes-local:1\")\n",
        "}\n",
        "\n",
        "my_job_outputs = {\n",
        "    \"datastore_data\": Output(type=AssetTypes.URI_FOLDER, path=\"azureml://datastores/blob_training_data/paths/datastore-path\")\n",
        "}\n",
        "\n",
        "# configure job\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python move-data.py --input_data ${{inputs.local_data}} --output_datastore ${{outputs.datastore_data}}\",\n",
        "    inputs=my_job_inputs,\n",
        "    outputs=my_job_outputs,\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"aml-cluster\",\n",
        "    display_name=\"move-diabetes-data\",\n",
        "    experiment_name=\"move-diabetes-data\"\n",
        ")\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}